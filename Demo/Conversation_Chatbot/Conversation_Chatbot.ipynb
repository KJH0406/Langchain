{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e03b1a8c-55c5-4ea7-a887-c9da9fafc7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install streamlit-chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bb4a7f4-a6b9-4122-9ab3-490747146a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "801dbecc-79f7-49ee-86fb-9c5cba09642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9677894-27b4-4c81-8ee9-db3e022fbb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2fb8f7c-d982-4d13-8e72-ce999cea3a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-18 14:34:05.413 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/anaconda3/envs/llm/lib/python3.8/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.vectorstores import FAISS\n",
    "import tempfile\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk\" #openai 키 입력\n",
    "\n",
    "uploaded_file = st.sidebar.file_uploader(\"upload\", type=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7de8204a-aae9-4df5-afd6-9be83d5b1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "if uploaded_file :\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
    "        tmp_file.write(uploaded_file.getvalue())\n",
    "        tmp_file_path = tmp_file.name\n",
    "    \n",
    "    loader = PyPDFLoader(tmp_file_path)\n",
    "    data = loader.load()\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectors = FAISS.from_documents(data, embeddings)\n",
    "\n",
    "    chain = ConversationalRetrievalChain.from_llm(llm = ChatOpenAI(temperature=0.0,model_name='gpt-4'), retriever=vectors.as_retriever())\n",
    "\n",
    "    def conversational_chat(query):  #문맥 유지를 위해 과거 대화 저장 이력에 대한 처리      \n",
    "        result = chain({\"question\": query, \"chat_history\": st.session_state['history']})\n",
    "        st.session_state['history'].append((query, result[\"answer\"]))        \n",
    "        return result[\"answer\"]\n",
    "    \n",
    "    if 'history' not in st.session_state:\n",
    "        st.session_state['history'] = []\n",
    "\n",
    "    if 'generated' not in st.session_state:\n",
    "        st.session_state['generated'] = [\"안녕하세요! \" + uploaded_file.name + \"에 관해 질문주세요.\"]\n",
    "\n",
    "    if 'past' not in st.session_state:\n",
    "        st.session_state['past'] = [\"안녕하세요!\"]\n",
    "        \n",
    "    #챗봇 이력에 대한 컨테이너\n",
    "    response_container = st.container()\n",
    "    #사용자가 입력한 문장에 대한 컨테이너\n",
    "    container = st.container()\n",
    "\n",
    "    with container: #대화 내용 저장(기억)\n",
    "        with st.form(key='Conv_Question', clear_on_submit=True):           \n",
    "            user_input = st.text_input(\"Query:\", placeholder=\"PDF파일에 대해 얘기해볼까요? (:\", key='input')\n",
    "            submit_button = st.form_submit_button(label='Send')\n",
    "            \n",
    "        if submit_button and user_input:\n",
    "            output = conversational_chat(user_input)\n",
    "            \n",
    "            st.session_state['past'].append(user_input)\n",
    "            st.session_state['generated'].append(output)\n",
    "\n",
    "    if st.session_state['generated']:\n",
    "        with response_container:\n",
    "            for i in range(len(st.session_state['generated'])):\n",
    "                message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user', avatar_style = \"fun-emoji\", seed = \"Nala\")\n",
    "                message(st.session_state[\"generated\"][i], key=str(i), avatar_style = \"bottts\", seed = \"Fluffy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c62e008-e8ac-427e-ad6c-cc814587d526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
